{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notebook para iniciar o projeto Classificação de Lesões de Pele utilizando Deep Learning.**\n",
    "\n",
    "<br>\n",
    "\n",
    "recentes:\n",
    "- download do dataset realizado (está na tinder: /home/ashiley/HAM10000_images_part_1 e /home/ashiley/HAM10000_images_part_2)\n",
    "\n",
    "DÚVIDAS:\n",
    "- estou com erro que diz ser necessário atualizar drive da gpu:\n",
    "\"RuntimeError: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.\"\n",
    "\n",
    "será que é realmente necessário? *posso fazer isso?*\n",
    "\n",
    "<br>\n",
    "\n",
    "caminho:\n",
    "* dividir dataset em treino / teste ok\n",
    "* declarar modelos ok's = (VGG, )\n",
    "* normalizar ok\n",
    "* definir criterio de loss, optimizer, realizar treinamento\n",
    "* ver acuracia com os dados de teste\n",
    "\n",
    "<br>\n",
    "\n",
    "anotações:\n",
    "* usar AlexNet, EfficientNet, Inception, LeNet, ResNet, VGG\n",
    "* usar torchvision & pytorch lightining \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (2.2.1)\n",
      "Requirement already satisfied: torchvision in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (0.17.1)\n",
      "Requirement already satisfied: pytorch-lightning in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (2.2.1)\n",
      "Requirement already satisfied: Pillow in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (10.2.0)\n",
      "Requirement already satisfied: pandas in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (2.2.1)\n",
      "Requirement already satisfied: efficientnet-pytorch in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (0.7.1)\n",
      "Requirement already satisfied: filelock in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (4.10.0)\n",
      "Requirement already satisfied: sympy in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from torch->-r requirements.txt (line 1)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 1)) (12.4.99)\n",
      "Requirement already satisfied: numpy in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from torchvision->-r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from pytorch-lightning->-r requirements.txt (line 3)) (4.66.2)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from pytorch-lightning->-r requirements.txt (line 3)) (6.0.1)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from pytorch-lightning->-r requirements.txt (line 3)) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from pytorch-lightning->-r requirements.txt (line 3)) (24.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from pytorch-lightning->-r requirements.txt (line 3)) (0.11.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 5)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 5)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 5)) (2024.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 3)) (3.9.3)\n",
      "Requirement already satisfied: setuptools in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from lightning-utilities>=0.8.0->pytorch-lightning->-r requirements.txt (line 3)) (68.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from jinja2->torch->-r requirements.txt (line 1)) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 3)) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 3)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 3)) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 3)) (1.9.4)\n",
      "Requirement already satisfied: idna>=2.0 in /home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 3)) (3.6)\n"
     ]
    }
   ],
   "source": [
    "# execute essa celula para instalar todos os requirements caso necessário.\n",
    "\n",
    "!pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pytorch_lightning\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA está disponível e 2 dispositivo(s) CUDA está(ão) disponível(is).\n"
     ]
    }
   ],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir_1, root_dir_2, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir_1 = root_dir_1\n",
    "        self.root_dir_2 = root_dir_2\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.annotations.iloc[idx, 1] + '.jpg'  \n",
    "        if img_name in os.listdir(self.root_dir_1):\n",
    "            img_path = os.path.join(self.root_dir_1, img_name)\n",
    "        else:\n",
    "            img_path = os.path.join(self.root_dir_2, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.annotations.iloc[idx, 2]\n",
    "        if label == 0:  \n",
    "            label = torch.tensor(0)\n",
    "        else:\n",
    "            label = torch.tensor(1)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Load CSV file and define paths\n",
    "csv_file = '/home/ashiley/HAM10000_metadata.csv'\n",
    "data_path_1 = '/home/ashiley/HAM10000_images_part_1'\n",
    "data_path_2 = '/home/ashiley/HAM10000_images_part_2'\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "# Create custom dataset instance\n",
    "custom_dataset = CustomDataset(csv_file=csv_file, root_dir_1=data_path_1, root_dir_2=data_path_2, transform=transform)\n",
    "\n",
    "# Create data loader\n",
    "data_loader = DataLoader(custom_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Verifica se CUDA está disponível\n",
    "cuda_available = torch.cuda.is_available()\n",
    "\n",
    "if cuda_available:\n",
    "    # Obtém o número de dispositivos CUDA disponíveis\n",
    "    num_cuda_devices = torch.cuda.device_count()\n",
    "    print(\"CUDA está disponível e {} dispositivo(s) CUDA está(ão) disponível(is).\".format(num_cuda_devices))\n",
    "else:\n",
    "    print(\"CUDA não está disponível. Você está executando em CPU.\")\n",
    "\n",
    "# Move um tensor para a GPU, se CUDA estiver disponível\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Concatenate datasets\n",
    "full_dataset = custom_dataset  # Assuming you have already defined custom_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the size of train and test sets\n",
    "train_size = int(0.8 * len(full_dataset)) # 80% for training\n",
    "test_size = len(full_dataset) - train_size # 20% for test\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoader for train and test sets\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definicoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = 3\n",
    "num_classes = 2  # malignant or benign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGGClassifier(\n",
      "  (vgg16): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (8): ReLU(inplace=True)\n",
      "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (11): ReLU(inplace=True)\n",
      "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (13): ReLU(inplace=True)\n",
      "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (15): ReLU(inplace=True)\n",
      "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (18): ReLU(inplace=True)\n",
      "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (20): ReLU(inplace=True)\n",
      "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (22): ReLU(inplace=True)\n",
      "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (25): ReLU(inplace=True)\n",
      "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (27): ReLU(inplace=True)\n",
      "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (29): ReLU(inplace=True)\n",
      "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Linear(in_features=4096, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class VGGClassifier(pl.LightningModule):\n",
    "    def __init__(self, num_classes):\n",
    "        super(VGGClassifier, self).__init__()\n",
    "        # Load the pretrained VGG16 model\n",
    "        self.vgg16 = models.vgg16(pretrained=True)\n",
    "        \n",
    "        # Modify the first layer to accept images\n",
    "        # depth (rgb = 3), number of filters \n",
    "        self.vgg16.features[0] = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Modify the classifier layer for the specified number of classes\n",
    "        num_features = self.vgg16.classifier[6].in_features\n",
    "        self.vgg16.classifier[6] = nn.Linear(num_features, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.vgg16(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = torch.sum(preds == y).item() / len(y)\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_acc', acc)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = torch.sum(preds == y).item() / len(y)\n",
    "        self.log('test_loss', loss)\n",
    "        self.log('test_acc', acc)\n",
    "\n",
    "vgg_model = VGGClassifier(num_classes)\n",
    "print(vgg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cuda_available \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Treinar o modelo\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Testar o modelo\u001b[39;00m\n\u001b[1;32m     11\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtest(test_dataloaders\u001b[38;5;241m=\u001b[39mtest_dataloader)\n",
      "File \u001b[0;32m~/miniconda3/envs/miniconda/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/miniconda/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/miniconda3/envs/miniconda/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    574\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    576\u001b[0m     ckpt_path,\n\u001b[1;32m    577\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/miniconda/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:943\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;66;03m# SET UP THE TRAINER\u001b[39;00m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    942\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: setting up strategy environment\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 943\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_environment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__setup_profiler()\n\u001b[1;32m    946\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: preparing data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/miniconda/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py:129\u001b[0m, in \u001b[0;36mStrategy.setup_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Setup any processes or distributed connections.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03mThis is called before the LightningModule/DataModule setup hook which allows the user to access the accelerator\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03menvironment before setup is complete.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_device\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/miniconda/lib/python3.12/site-packages/pytorch_lightning/accelerators/cuda.py:46\u001b[0m, in \u001b[0;36mCUDAAccelerator.setup_device\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDevice should be GPU, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m \u001b[43m_check_cuda_matmul_precision\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mset_device(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/miniconda/lib/python3.12/site-packages/lightning_fabric/accelerators/cuda.py:361\u001b[0m, in \u001b[0;36m_check_cuda_matmul_precision\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;129m@lru_cache\u001b[39m(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# show the warning only ever once\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_cuda_matmul_precision\u001b[39m(device: torch\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 361\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43m_is_ampere_or_later\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;66;03m# check that the user hasn't changed the precision already, this works for both `allow_tf32 = True` and\u001b[39;00m\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;66;03m# `set_float32_matmul_precision`\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/miniconda/lib/python3.12/site-packages/lightning_fabric/accelerators/cuda.py:355\u001b[0m, in \u001b[0;36m_is_ampere_or_later\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_ampere_or_later\u001b[39m(device: Optional[torch\u001b[38;5;241m.\u001b[39mdevice] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m--> 355\u001b[0m     major, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_device_capability\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m major \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/miniconda/lib/python3.12/site-packages/torch/cuda/__init__.py:439\u001b[0m, in \u001b[0;36mget_device_capability\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_capability\u001b[39m(device: Optional[_device_t] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m    427\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the cuda capability of a device.\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \n\u001b[1;32m    429\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;124;03m        tuple(int, int): the major and minor cuda capability of the device\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 439\u001b[0m     prop \u001b[38;5;241m=\u001b[39m \u001b[43mget_device_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m prop\u001b[38;5;241m.\u001b[39mmajor, prop\u001b[38;5;241m.\u001b[39mminor\n",
      "File \u001b[0;32m~/miniconda3/envs/miniconda/lib/python3.12/site-packages/torch/cuda/__init__.py:453\u001b[0m, in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_properties\u001b[39m(device: _device_t) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _CudaDeviceProperties:\n\u001b[1;32m    444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the properties of a device.\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \n\u001b[1;32m    446\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;124;03m        _CudaDeviceProperties: the properties of the device\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 453\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# will define _get_device_properties\u001b[39;00m\n\u001b[1;32m    454\u001b[0m     device \u001b[38;5;241m=\u001b[39m _get_device_index(device, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count():\n",
      "File \u001b[0;32m~/miniconda3/envs/miniconda/lib/python3.12/site-packages/torch/cuda/__init__.py:302\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    301\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 302\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    306\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver."
     ]
    }
   ],
   "source": [
    "# Instanciar o modelo\n",
    "model = VGGClassifier(num_classes)\n",
    "\n",
    "# Instanciar o treinador\n",
    "trainer = pl.Trainer(max_epochs=10, accelerator='gpu' if cuda_available else None)\n",
    "\n",
    "# Treinar o modelo\n",
    "trainer.fit(model, train_dataloader, test_dataloader)\n",
    "\n",
    "# Testar o modelo\n",
    "trainer.test(test_dataloaders=test_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(pl.LightningModule):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 6, kernel_size=5, stride=1)\n",
    "        self.avg_pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)\n",
    "        self.avg_pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(16, 120, kernel_size=5, stride=1)\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.fc2 = nn.Linear(84, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.conv1(x))\n",
    "        x = self.avg_pool1(x)\n",
    "        x = F.tanh(self.conv2(x))\n",
    "        x = self.avg_pool2(x)\n",
    "        x = F.tanh(self.conv3(x))\n",
    "        x = x.view(-1, 120)\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = torch.sum(preds == y).item() / (len(y) * 1.0)\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_acc', acc)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = torch.sum(preds == y).item() / (len(y) * 1.0)\n",
    "        self.log('test_loss', loss)\n",
    "        self.log('test_acc', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ResNetClassifier(pl.LightningModule):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNetClassifier, self).__init__()\n",
    "        # Load a pre-trained ResNet model\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "        \n",
    "        # Modify the last fully connected layer to match the number of classes\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(num_features, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = torch.sum(preds == y).item() / len(y)\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_acc', acc)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = torch.sum(preds == y).item() / len(y)\n",
    "        self.log('test_loss', loss)\n",
    "        self.log('test_acc', acc)\n",
    "        \n",
    "resnet_model = models.resnet18(num_classes=num_classes)\n",
    "print(resnet_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class AlexNetClassifier(pl.LightningModule):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(AlexNetClassifier, self).__init__()\n",
    "        self.alexnet = models.alexnet(pretrained=True)\n",
    "        \n",
    "        # Replace the classifier layer for the specified number of classes\n",
    "        num_features = self.alexnet.classifier[6].in_features\n",
    "        self.alexnet.classifier[6] = nn.Linear(num_features, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.alexnet(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = torch.sum(preds == y).item() / len(y)\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_acc', acc)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = torch.sum(preds == y).item() / len(y)\n",
    "        self.log('test_loss', loss)\n",
    "        self.log('test_acc', acc)\n",
    "        \n",
    "alexnet_model = models.alexnet(num_classes=num_classes)\n",
    "print(alexnet_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "EfficientNet(\n",
      "  (_conv_stem): Conv2dStaticSamePadding(\n",
      "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
      "    (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
      "  )\n",
      "  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "  (_blocks): ModuleList(\n",
      "    (0): MBConvBlock(\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
      "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (1): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
      "        (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (2): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
      "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (3): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
      "        (static_padding): ZeroPad2d((1, 2, 1, 2))\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (4): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
      "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (5): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
      "        (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (6-7): 2 x MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
      "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (8): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
      "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (9-10): 2 x MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
      "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (11): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
      "        (static_padding): ZeroPad2d((1, 2, 1, 2))\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (12-14): 3 x MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
      "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (15): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
      "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "  )\n",
      "  (_conv_head): Conv2dStaticSamePadding(\n",
      "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "    (static_padding): Identity()\n",
      "  )\n",
      "  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
      "  (_dropout): Dropout(p=0.2, inplace=False)\n",
      "  (_fc): Linear(in_features=1280, out_features=2, bias=True)\n",
      "  (_swish): MemoryEfficientSwish()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class EfficientNetClassifier(pl.LightningModule):\n",
    "    def __init__(self, num_classes):\n",
    "        super(EfficientNetClassifier, self).__init__()\n",
    "\n",
    "        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b0', num_classes=num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.efficientnet(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = torch.sum(preds == y).item() / len(y)\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_acc', acc)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = torch.sum(preds == y).item() / len(y)\n",
    "        self.log('test_loss', loss)\n",
    "        self.log('test_acc', acc)\n",
    "        \n",
    "efficientnet_model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=num_classes)       \n",
    "print(efficientnet_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ashiley/miniconda3/envs/miniconda/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /home/ashiley/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n",
      "100%|██████████| 104M/104M [00:10<00:00, 10.8MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InceptionClassifier(\n",
      "  (inception): Inception3(\n",
      "    (Conv2d_1a_3x3): BasicConv2d(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (Conv2d_2a_3x3): BasicConv2d(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (Conv2d_2b_3x3): BasicConv2d(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (Conv2d_3b_1x1): BasicConv2d(\n",
      "      (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (Conv2d_4a_3x3): BasicConv2d(\n",
      "      (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (Mixed_5b): InceptionA(\n",
      "      (branch1x1): BasicConv2d(\n",
      "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch5x5_1): BasicConv2d(\n",
      "        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch5x5_2): BasicConv2d(\n",
      "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch3x3dbl_1): BasicConv2d(\n",
      "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch3x3dbl_2): BasicConv2d(\n",
      "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch3x3dbl_3): BasicConv2d(\n",
      "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch_pool): BasicConv2d(\n",
      "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (Mixed_5c): InceptionA(\n",
      "      (branch1x1): BasicConv2d(\n",
      "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch5x5_1): BasicConv2d(\n",
      "        (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch5x5_2): BasicConv2d(\n",
      "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch3x3dbl_1): BasicConv2d(\n",
      "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch3x3dbl_2): BasicConv2d(\n",
      "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch3x3dbl_3): BasicConv2d(\n",
      "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch_pool): BasicConv2d(\n",
      "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (Mixed_5d): InceptionA(\n",
      "      (branch1x1): BasicConv2d(\n",
      "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch5x5_1): BasicConv2d(\n",
      "        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch5x5_2): BasicConv2d(\n",
      "        (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch3x3dbl_1): BasicConv2d(\n",
      "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch3x3dbl_2): BasicConv2d(\n",
      "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch3x3dbl_3): BasicConv2d(\n",
      "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch_pool): BasicConv2d(\n",
      "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (Mixed_6a): InceptionB(\n",
      "      (branch3x3): BasicConv2d(\n",
      "        (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch3x3dbl_1): BasicConv2d(\n",
      "        (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch3x3dbl_2): BasicConv2d(\n",
      "        (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch3x3dbl_3): BasicConv2d(\n",
      "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (Mixed_6b): InceptionC(\n",
      "      (branch1x1): BasicConv2d(\n",
      "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7_1): BasicConv2d(\n",
      "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7_2): BasicConv2d(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7_3): BasicConv2d(\n",
      "        (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7dbl_1): BasicConv2d(\n",
      "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7dbl_2): BasicConv2d(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7dbl_3): BasicConv2d(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7dbl_4): BasicConv2d(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7dbl_5): BasicConv2d(\n",
      "        (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch_pool): BasicConv2d(\n",
      "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (Mixed_6c): InceptionC(\n",
      "      (branch1x1): BasicConv2d(\n",
      "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7_1): BasicConv2d(\n",
      "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7_2): BasicConv2d(\n",
      "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7_3): BasicConv2d(\n",
      "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7dbl_1): BasicConv2d(\n",
      "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7dbl_2): BasicConv2d(\n",
      "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7dbl_3): BasicConv2d(\n",
      "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7dbl_4): BasicConv2d(\n",
      "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7dbl_5): BasicConv2d(\n",
      "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch_pool): BasicConv2d(\n",
      "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (Mixed_6d): InceptionC(\n",
      "      (branch1x1): BasicConv2d(\n",
      "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7_1): BasicConv2d(\n",
      "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7_2): BasicConv2d(\n",
      "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7_3): BasicConv2d(\n",
      "        (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7dbl_1): BasicConv2d(\n",
      "        (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7dbl_2): BasicConv2d(\n",
      "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7dbl_3): BasicConv2d(\n",
      "        (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7dbl_4): BasicConv2d(\n",
      "        (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7dbl_5): BasicConv2d(\n",
      "        (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch_pool): BasicConv2d(\n",
      "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (Mixed_6e): InceptionC(\n",
      "      (branch1x1): BasicConv2d(\n",
      "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7_1): BasicConv2d(\n",
      "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7_2): BasicConv2d(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7_3): BasicConv2d(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7dbl_1): BasicConv2d(\n",
      "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7dbl_2): BasicConv2d(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7dbl_3): BasicConv2d(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7dbl_4): BasicConv2d(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7dbl_5): BasicConv2d(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch_pool): BasicConv2d(\n",
      "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (AuxLogits): InceptionAux(\n",
      "      (conv0): BasicConv2d(\n",
      "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv1): BasicConv2d(\n",
      "        (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
      "    )\n",
      "    (Mixed_7a): InceptionD(\n",
      "      (branch3x3_1): BasicConv2d(\n",
      "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch3x3_2): BasicConv2d(\n",
      "        (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7x3_1): BasicConv2d(\n",
      "        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7x3_2): BasicConv2d(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7x3_3): BasicConv2d(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch7x7x3_4): BasicConv2d(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (Mixed_7b): InceptionE(\n",
      "      (branch1x1): BasicConv2d(\n",
      "        (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch3x3_1): BasicConv2d(\n",
      "        (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch3x3_2a): BasicConv2d(\n",
      "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch3x3_2b): BasicConv2d(\n",
      "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch3x3dbl_1): BasicConv2d(\n",
      "        (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch3x3dbl_2): BasicConv2d(\n",
      "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch3x3dbl_3a): BasicConv2d(\n",
      "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch3x3dbl_3b): BasicConv2d(\n",
      "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch_pool): BasicConv2d(\n",
      "        (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (Mixed_7c): InceptionE(\n",
      "      (branch1x1): BasicConv2d(\n",
      "        (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch3x3_1): BasicConv2d(\n",
      "        (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch3x3_2a): BasicConv2d(\n",
      "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch3x3_2b): BasicConv2d(\n",
      "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch3x3dbl_1): BasicConv2d(\n",
      "        (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch3x3dbl_2): BasicConv2d(\n",
      "        (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch3x3dbl_3a): BasicConv2d(\n",
      "        (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch3x3dbl_3b): BasicConv2d(\n",
      "        (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (branch_pool): BasicConv2d(\n",
      "        (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class InceptionClassifier(pl.LightningModule):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.inception = models.inception_v3(pretrained=True)\n",
    "        \n",
    "        # Replace the classifier layer for the specified number of classes\n",
    "        in_features = self.inception.fc.in_features\n",
    "        self.inception.fc = nn.Linear(in_features, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.inception(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = torch.sum(preds == y).item() / len(y)\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_acc', acc)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = torch.sum(preds == y).item() / len(y)\n",
    "        self.log('test_loss', loss)\n",
    "        self.log('test_acc', acc)\n",
    "        \n",
    "# Instantiate the model\n",
    "inception_model = InceptionClassifier(num_classes=2)\n",
    "print(inception_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
